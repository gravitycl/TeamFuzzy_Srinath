{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded!\n",
      "\n",
      "ğŸ” Running predictions on sample images...\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step\n",
      "Image: ny1157-01-1.jpg\n",
      "ğŸ”¹ Actual:    Abies concolor\n",
      "ğŸ”¸ Predicted: Picea pungens\n",
      "----------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Image: ny1157-01-2.jpg\n",
      "ğŸ”¹ Actual:    Abies concolor\n",
      "ğŸ”¸ Predicted: Picea pungens\n",
      "----------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Image: ny1157-01-3.jpg\n",
      "ğŸ”¹ Actual:    Abies concolor\n",
      "ğŸ”¸ Predicted: Abies concolor\n",
      "----------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Image: ny1157-01-4.jpg\n",
      "ğŸ”¹ Actual:    Abies concolor\n",
      "ğŸ”¸ Predicted: Abies concolor\n",
      "----------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Image: ny1157-02-1.jpg\n",
      "ğŸ”¹ Actual:    Abies concolor\n",
      "ğŸ”¸ Predicted: Abies concolor\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# CONFIG\n",
    "MODEL_PATH = \"/Users/drago/plant_detector/plant_model.h5\"\n",
    "DATASET_ROOT = \"/Users/drago/plant_detector/leafsnap-dataset\"\n",
    "METADATA_PATH = f\"{DATASET_ROOT}/leafsnap-dataset-images.txt\"\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# Load model\n",
    "model = load_model(MODEL_PATH)\n",
    "print(\"âœ… Model loaded!\")\n",
    "\n",
    "# Load metadata to get sample test images\n",
    "df = pd.read_csv(METADATA_PATH, sep='\\t')\n",
    "\n",
    "# Clean/validate image paths\n",
    "valid_images = []\n",
    "for _, row in df.iterrows():\n",
    "    img_path = os.path.join(DATASET_ROOT, row['image_path'])\n",
    "    seg_path = os.path.join(DATASET_ROOT, row['segmented_path'])\n",
    "    if os.path.exists(img_path):\n",
    "        valid_images.append((img_path, row['species']))\n",
    "    elif os.path.exists(seg_path):\n",
    "        valid_images.append((seg_path, row['species']))\n",
    "\n",
    "# Take first N test cases\n",
    "test_samples = valid_images[:5]\n",
    "\n",
    "# Label encoder\n",
    "species_list = sorted(list(set([s for _, s in valid_images])))\n",
    "species_to_idx = {s: i for i, s in enumerate(species_list)}\n",
    "idx_to_species = {i: s for s, i in species_to_idx.items()}\n",
    "\n",
    "# Prediction function\n",
    "def predict_image(path):\n",
    "    raw = tf.io.read_file(path)\n",
    "    is_jpeg = tf.strings.regex_full_match(path, \".*\\.jpe?g\")\n",
    "    image = tf.cond(\n",
    "        is_jpeg,\n",
    "        lambda: tf.image.decode_jpeg(raw, channels=3),\n",
    "        lambda: tf.image.decode_png(raw, channels=3)\n",
    "    )\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize_with_pad(image, IMG_SIZE, IMG_SIZE)\n",
    "    image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    prediction = model.predict(image)\n",
    "    predicted_index = tf.argmax(prediction, axis=1).numpy()[0]\n",
    "    predicted_species = idx_to_species[predicted_index]\n",
    "    return predicted_species\n",
    "\n",
    "# Run predictions\n",
    "print(\"\\nğŸ” Running predictions on sample images...\\n\")\n",
    "for path, true_species in test_samples:\n",
    "    predicted = predict_image(path)\n",
    "    print(f\"Image: {os.path.basename(path)}\")\n",
    "    print(f\"ğŸ”¹ Actual:    {true_species}\")\n",
    "    print(f\"ğŸ”¸ Predicted: {predicted}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
